\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{polski}

\usepackage[letterpaper,top=3cm,bottom=3cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

\title{Warsztaty z technik uczenia maszynowego}
\author{Wojciech Klusek, Aleksander Kuś}
\date{24 May 2022}

\begin{document}

\maketitle

\section{Wstęp}
Celem projektu było zaimplementowanie algorytmu ROCKET (RandOm Convolutional KErnel Transform) w języku R dla szeregów wielu zmiennych przy założeniu, że obserwacje mogą mieć różne długości. Algorytm ROCKET służy do klasyfikacji szeregów czasowych z wykorzystaniem dużych ilości losowych "kerneli", które mają parametry takie jak: "length", "weights, "bias", "dilation" oraz "padding".

\section{Przygotowanie danych}
Wstępne dane zostały pobrane ze strony timeseriesclassification.com. Do testów użyliśmy zestawów danych BasicMotions, Epilepsy, Handwriting oraz NATOP. Następnie pobrane dane przycięliśmy tak, aby obserwacje miały różne długości zgodnie z następującymi zasadami: 

\subsubsection*{Dla każdej klasy}
\begin{itemize}
  \item 1/3 instancji będzie miała długość [10\%,40\%] oryginalnej długości
  \item 1/3 instancji będzie miała długość (40\%,70\%] oryginalnej długości
  \item 1/3 instancji będzie miała długość (70\%,100\%] oryginalnej długości
\end{itemize}

Skrócone instancje zostały następnie wypełnione średnią arytmetyczną wartości, które nie zostały przycięte dla danej instancji lub zerami.

\section{Opis algorytmu ROCKET}
Na wstępie generowana jest zadana ilość "kerneli" z odpowiednimi parametrami. Następnie są one aplikowane do danych treningowych oraz testowych. "Kernel" ma następujące parametry:

\begin{itemize}
  \item "Length" - losowo wybrana liczba ze zbioru \{ 7, 9, 11 \}
  \item "Weights" - wartości z rozkładu normalnego $X \sim \mathcal{N}(0,1)$
  \item "Bias" - wartość z rozkładu jednostajnego ciągłego $\mathcal{U}(0,1)$
  \item "Dilation" - jest próbkowana w skali wykładniczej $d=\lfloor2^x\rfloor$, $x \sim \mathcal{U}(0,A)$, gdzie $A=\log_2\frac{l_input-1}{l_kernel-1}$
  \item "Padding" - w momencie generacji "kernela" podejmowana jest losowa decyzja czy "padding" ma zostać użyty w momencie aplikowania "kernela" czy też nie. Bez paddingu "kernele" nie są wyśrodkowane w pierwszych i ostatnich $ \lfloor l_{kernel} - 1 \rfloor $ punktów.
\end{itemize}

Każdy "kernel" ($\omega$) z "Dilation" (d) jest aplikowany do każdego wejściowego szeregu czasowego (X) od pozycji i, według następującego wzoru: 
$$X_{i} * \omega =  \sum_{j=0}^{l_{kernel} - 1} X_{i + (j \times	d)} \times	\omega_{j}. $$ 

Rocket oblicza dwie zagregowane cechy z każdej mapy cech, tworząc
dwie liczby rzeczywiste dla każdego "kernela":

\begin{itemize}
  \item maksymalna wartość
  \item odsetek wartości dodatnich (ppv) 
\end{itemize}

\section{Uruchomienie programu}
Do uruchomienia programu wymagane są następujące biblioteki:

\subsubsection*{Dla R}
\begin{itemize}
  \item foreign
  \item reticulate
\end{itemize}

Dla pakietu reticulate wymagana jest instalacja programu "miniconda". Pakiet ten wykorzystywany jest dla funkcji "array\_reshape()", której odpowiednika nie znaleźliśmy w czystym języku R.

Instalacja powyższych zależności:
\begin{verbatim}
    install.packages(c("foreign", "reticulate"))
    library("reticulate")
    install_miniconda()
\end{verbatim}

\subsubsection*{Dla Pythona}
\begin{itemize}
  \item sktime
  \item numpy
\end{itemize}

Z biblioteki sktime wykorzystywana jest klasa RidgeClassifierCV używana do oceniania poprawności algorytmu. Do uruchomienia projektu użyliśmy środowiska PyCharm Community, uruchamiając plik run.py.

\section{Przeprowadzone testy}

Dla każdego wyżej opisanego zbioru danych przycięliśmy zbiory "train" i "test" według schematu opisanego powyżej oraz uruchomiliśmy nasz algorytm. Następnie wyniki przekazaliśmy do klasyfikatora w celu oceny. Proces ten powtórzyliśmy 10 razy z uwagi na brak determinizmu etapu przycinania danych, a otrzymane wyniki uśredniliśmy. Wyniki przedstawiono poniżej.

\section{Wyniki}
Wyniki zostały wyznaczone dla 100 "kerneli"

\subsubsection*{BasicMotions}
Parametry zbioru danych:
\begin{itemize}
  \item długość instancji TRAIN: 40
  \item długość instancji TEST: 40
  \item Długość szeregów: 100
\end{itemize}

\begin{center}
\begin{tabular}{|c c c c|} 
 \hline
 Numer próby & Wynik dla średniej & Wynik dla zer & Wynik referencyjny \\ [0.5ex] 
 \hline\hline
 1 & 0.875 & 0.875 & 0.9 \\ 
 \hline
 2 & 0.9 & 0.95 & 0.9 \\
 \hline
 3 & 0.9 & 0.9 & 0.9 \\
 \hline
 4 & 0.9 & 0.875 & 0.9 \\
 \hline
  5 & 0.95 & 0.95 & 0.9 \\
 \hline
  6 & 0.875 & 0.9 & 0.9 \\
 \hline
  7 & 0.9 & 0.9 & 0.9 \\
 \hline
  8 & 0.875 & 0.9 & 0.9 \\
 \hline
  9 & 0.975 & 0.975 & 0.9 \\
 \hline
  10 & 0.975 & 0.975 & 0.9 \\
 \hline
 Średnia & 0.9125 & 0.920 & 0.9 \\
 \hline
\end{tabular}
\end{center}

\subsubsection*{Epilepsy}
Parametry zbioru danych:
\begin{itemize}
  \item długość instancji TRAIN: 137
  \item długość instancji TEST: 138
  \item Długość szeregów: 206
\end{itemize}

\begin{center}
\begin{tabular}{|c c c c|} 
 \hline
 Numer próby & Wynik dla średniej & Wynik dla zer & Wynik referencyjny \\ [0.5ex] 
 \hline
 1 & 0.913 & 0.891 & 0.942 \\ 
 \hline
 2 & 0.876 & 0.876 & 0.942 \\
 \hline
 3 & 0.884 & 0.876 & 0.942 \\
 \hline
 4 & 0.905 & 0.891 & 0.942 \\
 \hline
  5 & 0.898 & 0.905 & 0.942 \\
 \hline
  6 & 0.876 & 0.847 & 0.942 \\
 \hline
  7 & 0.905 & 0.891 & 0.942 \\
 \hline
  8 & 0.891 & 0.884 & 0.942 \\
 \hline
  9 & 0.855 & 0.833 & 0.942 \\
 \hline
  10 & 0.855 & 0.876 & 0.942 \\
 \hline
 Średnia & 0.886 & 0.877 & 0.942 \\
 \hline
\end{tabular}
\end{center}

\subsubsection*{Handwriting}
Parametry zbioru danych:
\begin{itemize}
  \item długość instancji TRAIN: 150
  \item długość instancji TEST: 850
  \item Długość szeregów: 152
\end{itemize}

\begin{center}
\begin{tabular}{|c c c c|} 
 \hline
 Numer próby & Wynik dla średniej & Wynik dla zer & Wynik referencyjny \\ [0.5ex] 
 \hline\hline
 1 & 0.191 & 0.197 & 0.248 \\ 
 \hline
 2 & 0.192 & 0.191 & 0.248 \\
 \hline
 3 & 0.197 & 0.196 & 0.248 \\
 \hline
 4 & 0.192 & 0.197 & 0.248 \\
 \hline
  5 & 0.198 & 0.202 & 0.248 \\
 \hline
  6 & 0.182 & 0.192 & 0.248 \\
 \hline
  7 & 0.201 & 0.202 & 0.248 \\
 \hline
  8 & 0.202 & 0.204 & 0.248 \\
 \hline
  9 & 0.187 & 0.187 & 0.248 \\
 \hline
  10 & 0.190 & 0.195 & 0.248 \\
 \hline
 Średnia & 0.193 & 0.196 & 0.248 \\
 \hline
\end{tabular}
\end{center}

\subsubsection*{NATOPS}
Parametry zbioru danych:
\begin{itemize}
  \item długość instancji TRAIN: 180
  \item długość instancji TEST: 180
  \item Długość szeregów: 51
\end{itemize}

\begin{center}
\begin{tabular}{|c c c c|} 
 \hline
 Numer próby & Wynik dla średniej & Wynik dla zer & Wynik referencyjny \\ [0.5ex] 
 \hline\hline
 1 & 0.605 & 0.605 & 0.827 \\
 \hline
 2 & 0.611 & 0.661 & 0.827 \\
 \hline
 3 & 0.605 & 0.627 & 0.827 \\
 \hline
 4 & 0.577 & 0.638 & 0.827 \\
 \hline
  5 & 0.594 & 0.65 & 0.827 \\
 \hline
  6 & 0.594 & 0.661 & 0.827 \\
 \hline
  7 & 0.594 & 0.65 & 0.827 \\
 \hline
  8 & 0.633 & 0.633 & 0.827 \\
 \hline
  9 & 0.6 & 0.577 & 0.827 \\
 \hline
  10 & 0.6 & 0.661 & 0.827 \\
 \hline
 Średnia & 0.601 & 0.636 & 0.827 \\
 \hline
\end{tabular}
\end{center}

\section{Wnioski}

Z przeprowadzonych eksperymentów wynika, że dokładność algorytmu dla danych nieobciętych jest największa. Obcinanie danych i wypełnianie obciętych wartości zerami daje lepsze rezultaty niż wypełnianie wartością średnią pozostałych elementów. Dla zbioru "Handwriting", dla którego ilość instancji w zbiorze treningowym jest dużo mniejsza od tych w zbiorze testowym, dokładność była najmniejsza. Obcinanie danych ma różny wpływ na dokładność w różnych zbiorach. W zbiorze NATOPS, gdzie długość szeregów była najmniejsza, obcinanie danych miało największy wpływ.

\section{Bibliografia}

\begingroup
\renewcommand{\section}[2]{}%
\begin{thebibliography}{9}

\bibitem{sk1}
https://github.com/alan-turing-institute/sktime/blob/main/

sktime/transformations/panel/rocket/\_rocket.py

\bibitem{sk2}
https://github.com/alan-turing-institute/sktime/blob/main/

examples/rocket.ipynb

\bibitem{ang1}
https://github.com/angus924/rocket
\end{thebibliography}
\endgroup

\end{document}
